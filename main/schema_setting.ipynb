{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the database schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessory library and build functions for the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from functools import wraps\n",
    "from sqlalchemy.exc import OperationalError, SQLAlchemyError\n",
    "from main.database_utils import DatabaseConnector\n",
    "from sqlalchemy import text, create_engine, MetaData, Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaUpdater(DatabaseConnector):\n",
    "    \"\"\"\n",
    "    A class to update the schema of a table in a database based on desired changes.\n",
    "\n",
    "    Inherits from:\n",
    "    -------------\n",
    "    DatabaseConnector:\n",
    "        A base class to handle database connections.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    creds : dict\n",
    "        Database credentials obtained from the credentials file.\n",
    "    engine : sqlalchemy.engine.Engine\n",
    "        SQLAlchemy engine initialized from the credentials.\n",
    "    schema : dict\n",
    "        The current schema of the table, with column names as keys and their data types as values.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    get_schema(connection, table_name):\n",
    "        Retrieves the schema for a specific table.\n",
    "    \n",
    "    update_schema(connection, table_name, desired_schema):\n",
    "        Updates the schema of a given table based on a desired schema dictionary.\n",
    "    \"\"\"\n",
    "    def __init__(self, target_creds_path=\"target_db_creds.yaml\"):\n",
    "    # def __init__(self, creds_path=\"db_creds.yaml\", target_creds_path=\"target_db_creds.yaml\"):\n",
    "        super().__init__(target_creds_path)\n",
    "        self.creds = self.read_db_creds(target_creds_path)\n",
    "\n",
    "    def get_schema(self, connection, table_name):\n",
    "        metadata = MetaData()\n",
    "        table = Table(table_name, metadata, autoload_with=connection)\n",
    "        self.schema = {column.name: str(column.type) for column in table.columns}\n",
    "\n",
    "    def update_schema(self, connection, table_name, desired_schema):\n",
    "        \"\"\"\n",
    "        Updates the schema of the specified table based on the desired schema.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        connection : sqlalchemy.engine.Connection\n",
    "            The connection to the database.\n",
    "        table_name : str\n",
    "            The name of the table to update.\n",
    "        desired_schema : dict\n",
    "            A dictionary containing the desired schema for the table.\n",
    "        \"\"\"\n",
    "        # Retrieve the current schema for the table\n",
    "        self.get_schema(connection, table_name)\n",
    "        print(f\"Original schema for table {table_name}: {self.schema}\")\n",
    "\n",
    "        # Compare and prepare schema changes if necessary\n",
    "        alter_statements = []\n",
    "        for column, desired_type in desired_schema.items():\n",
    "            current_type = self.schema.get(column)\n",
    "            print(f\"Checking column '{column}': current type is '{current_type}', desired type is '{desired_type}'\")\n",
    "\n",
    "            if current_type != desired_type:\n",
    "                alter_statements.append(\n",
    "                    f\"ALTER COLUMN {column} SET DATA TYPE {desired_type} USING {column}::{desired_type}\"\n",
    "                )\n",
    "\n",
    "        if alter_statements:\n",
    "            sql_command = f\"ALTER TABLE {table_name} {', '.join(alter_statements)};\"\n",
    "            print(f\"Executing SQL: {sql_command}\")\n",
    "\n",
    "            try:\n",
    "                connection.execute(text(sql_command))\n",
    "                connection.commit() \n",
    "                print(f\"Schema updates applied successfully for {table_name}.\")\n",
    "                self.get_schema(connection, table_name)\n",
    "                print(f\"Current schema for table {table_name}: {self.schema}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error applying schema updates for {table_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"No additional schema changes needed for {table_name}.\")\n",
    "\n",
    "def get_max_lengths(connection, table_name, columns):\n",
    "    \"\"\"\n",
    "    Retrieves the maximum length of data in each specified column of a given table.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    engine : sqlalchemy.engine.Engine\n",
    "        The SQLAlchemy engine used to connect to the database.\n",
    "    table_name : str\n",
    "        The name of the table to query.\n",
    "    columns : list of str\n",
    "        A list of column names for which to calculate the maximum data length.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict:\n",
    "        A dictionary where each key is a column name and its corresponding value is the \n",
    "        maximum length of the data in that column. If the column has no data, the length is 0.\n",
    "    \n",
    "    Example:\n",
    "    -------\n",
    "    >>> max_lengths = get_max_lengths(engine, 'products_table', ['product_name', 'category'])\n",
    "    >>> print(max_lengths)\n",
    "    {'product_name': 50, 'category': 30}\n",
    "    \"\"\"\n",
    "    max_lengths = {}\n",
    "    for column in columns:\n",
    "        result = connection.execute(text(f\"\"\"\n",
    "            SELECT MAX(LENGTH({column})) AS max_length\n",
    "            FROM {table_name}\n",
    "            WHERE {column} IS NOT NULL;\n",
    "        \"\"\"))\n",
    "        max_length = result.scalar() or 0  # Default to 0 if no data\n",
    "        max_lengths[column] = max_length\n",
    "    return max_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SchemaUpdater\n",
    "su = SchemaUpdater()\n",
    "# Read target credentials\n",
    "su.creds = su.read_db_creds(su.target_creds_path)\n",
    "# Create engine\n",
    "su.engine = create_engine(\n",
    "    f\"postgresql://{su.creds['RDS_USER']}:{su.creds['RDS_PASSWORD']}@{su.creds['RDS_HOST']}:{su.creds['RDS_PORT']}/{su.creds['RDS_DATABASE']}\"\n",
    ")\n",
    "# Using the SchemaUpdater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Change the data types of columns in \"orders_table\" to correspond to those seen in the table below.\n",
    "```\n",
    "+------------------+--------------------+--------------------+\n",
    "|   orders_table   | current data type  | required data type |\n",
    "+------------------+--------------------+--------------------+\n",
    "| date_uuid        | TEXT               | UUID               |\n",
    "| user_uuid        | TEXT               | UUID               |\n",
    "| card_number      | TEXT               | VARCHAR(?)         |\n",
    "| store_code       | TEXT               | VARCHAR(?)         |\n",
    "| product_code     | TEXT               | VARCHAR(?)         |\n",
    "| product_quantity | BIGINT             | SMALLINT           |\n",
    "+------------------+--------------------+--------------------+\n",
    "```\n",
    "\n",
    "The ? in VARCHAR should be replaced with an integer representing the maximum length of the values in that column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original schema for table orders_table: {'level_0': 'BIGINT', 'index': 'BIGINT', 'date_uuid': 'TEXT', 'user_uuid': 'TEXT', 'card_number': 'TEXT', 'store_code': 'TEXT', 'product_code': 'TEXT', 'product_quantity': 'TEXT'}\n",
      "Checking column 'user_uuid': current type is 'TEXT', desired type is 'UUID'\n",
      "Checking column 'date_uuid': current type is 'TEXT', desired type is 'UUID'\n",
      "Checking column 'card_number': current type is 'TEXT', desired type is 'VARCHAR(19)'\n",
      "Checking column 'store_code': current type is 'TEXT', desired type is 'VARCHAR(12)'\n",
      "Checking column 'product_code': current type is 'TEXT', desired type is 'VARCHAR(11)'\n",
      "Checking column 'product_quantity': current type is 'TEXT', desired type is 'SMALLINT'\n",
      "Executing SQL: ALTER TABLE orders_table ALTER COLUMN user_uuid SET DATA TYPE UUID USING user_uuid::UUID, ALTER COLUMN date_uuid SET DATA TYPE UUID USING date_uuid::UUID, ALTER COLUMN card_number SET DATA TYPE VARCHAR(19) USING card_number::VARCHAR(19), ALTER COLUMN store_code SET DATA TYPE VARCHAR(12) USING store_code::VARCHAR(12), ALTER COLUMN product_code SET DATA TYPE VARCHAR(11) USING product_code::VARCHAR(11), ALTER COLUMN product_quantity SET DATA TYPE SMALLINT USING product_quantity::SMALLINT;\n",
      "Schema updates applied successfully for orders_table.\n",
      "Current schema for table orders_table: {'level_0': 'BIGINT', 'index': 'BIGINT', 'date_uuid': 'UUID', 'user_uuid': 'UUID', 'card_number': 'VARCHAR(19)', 'store_code': 'VARCHAR(12)', 'product_code': 'VARCHAR(11)', 'product_quantity': 'SMALLINT'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you already have your connection and table name\n",
    "columns_to_check = ['card_number', 'store_code', 'product_code']\n",
    "# max_lengths = get_max_lengths(connection, 'orders_table', columns_to_check)\n",
    "# Define the desired schema for the table\n",
    "\n",
    "\n",
    "# build connection with database\n",
    "with su.engine.connect() as connection:\n",
    "    # max_lengths = get_max_lengths(connection, 'orders_table', columns_to_check)\n",
    "    max_lengths = get_max_lengths(connection, 'orders_table', columns_to_check)\n",
    "    # Define the desired schema for the table\n",
    "    desired_orders_table_schema = {\n",
    "        'user_uuid': 'UUID',\n",
    "        'date_uuid': 'UUID',\n",
    "        'card_number': f'VARCHAR({max_lengths[\"card_number\"]})',\n",
    "        'store_code': f'VARCHAR({max_lengths[\"store_code\"]})',\n",
    "        'product_code': f'VARCHAR({max_lengths[\"product_code\"]})',\n",
    "        'product_quantity': 'SMALLINT'\n",
    "    }\n",
    "    # Alter the specific table schema in that database\n",
    "    su.update_schema(connection, 'orders_table', desired_orders_table_schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Re-schema \"dim_users\" as seen in the table below.\n",
    "\n",
    "```\n",
    "The column required to be changed in the users table are as follows:\n",
    "\n",
    "+----------------+--------------------+--------------------+\n",
    "| dim_users      | current data type  | required data type |\n",
    "+----------------+--------------------+--------------------+\n",
    "| first_name     | TEXT               | VARCHAR(255)       |\n",
    "| last_name      | TEXT               | VARCHAR(255)       |\n",
    "| date_of_birth  | TEXT               | DATE               |\n",
    "| country_code   | TEXT               | VARCHAR(?)         |\n",
    "| user_uuid      | TEXT               | UUID               |\n",
    "| join_date      | TEXT               | DATE               |\n",
    "+----------------+--------------------+--------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original schema for table dim_users: {'index': 'BIGINT', 'first_name': 'TEXT', 'last_name': 'TEXT', 'date_of_birth': 'DATE', 'company': 'TEXT', 'email_address': 'TEXT', 'address': 'TEXT', 'country': 'TEXT', 'country_code': 'TEXT', 'phone_number': 'TEXT', 'join_date': 'DATE', 'user_uuid': 'TEXT'}\n",
      "Checking column 'first_name': current type is 'TEXT', desired type is 'VARCHAR(255)'\n",
      "Checking column 'last_name': current type is 'TEXT', desired type is 'VARCHAR(255)'\n",
      "Checking column 'date_of_birth': current type is 'DATE', desired type is 'DATE'\n",
      "Checking column 'country_code': current type is 'TEXT', desired type is 'VARCHAR(2)'\n",
      "Checking column 'user_uuid': current type is 'TEXT', desired type is 'UUID'\n",
      "Checking column 'join_date': current type is 'DATE', desired type is 'DATE'\n",
      "Executing SQL: ALTER TABLE dim_users ALTER COLUMN first_name SET DATA TYPE VARCHAR(255) USING first_name::VARCHAR(255), ALTER COLUMN last_name SET DATA TYPE VARCHAR(255) USING last_name::VARCHAR(255), ALTER COLUMN country_code SET DATA TYPE VARCHAR(2) USING country_code::VARCHAR(2), ALTER COLUMN user_uuid SET DATA TYPE UUID USING user_uuid::UUID;\n",
      "Schema updates applied successfully for dim_users.\n",
      "Current schema for table dim_users: {'index': 'BIGINT', 'first_name': 'VARCHAR(255)', 'last_name': 'VARCHAR(255)', 'date_of_birth': 'DATE', 'company': 'TEXT', 'email_address': 'TEXT', 'address': 'TEXT', 'country': 'TEXT', 'country_code': 'VARCHAR(2)', 'phone_number': 'TEXT', 'join_date': 'DATE', 'user_uuid': 'UUID'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# build connection with database\n",
    "with su.engine.connect() as connection:\n",
    "    columns_to_check = [\"country_code\"]\n",
    "    max_lengths = get_max_lengths(connection, 'dim_users', columns_to_check)\n",
    "    # Define the desired schema for the table\n",
    "    desired_users_table_schema = {\n",
    "        'first_name': 'VARCHAR(255)',\n",
    "        'last_name': 'VARCHAR(255)',\n",
    "        'date_of_birth': 'DATE',\n",
    "        'country_code': f'VARCHAR({max_lengths[\"country_code\"]})',\n",
    "        'user_uuid': 'UUID',\n",
    "        'join_date': 'DATE'\n",
    "    }\n",
    "    # Alter the specific table schema in that database\n",
    "    su.update_schema(connection, 'dim_users', desired_users_table_schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Re-schema \"dim_store_details\" as seen in the table below.\n",
    "There are two latitude columns in the store details table. Using SQL, merge one of the columns into the other so you have one latitude column.\n",
    "\n",
    "Then set the data types for each column as shown below:\n",
    "```\n",
    "+---------------------+-------------------+------------------------+\n",
    "| store_details_table | current data type |   required data type   |\n",
    "+---------------------+-------------------+------------------------+\n",
    "| longitude           | TEXT              | FLOAT                  |\n",
    "| locality            | TEXT              | VARCHAR(255)           |\n",
    "| store_code          | TEXT              | VARCHAR(?)             |\n",
    "| staff_numbers       | TEXT              | SMALLINT               |\n",
    "| opening_date        | TEXT              | DATE                   |\n",
    "| store_type          | TEXT              | VARCHAR(255) NULLABLE  |\n",
    "| latitude            | TEXT              | FLOAT                  |\n",
    "| country_code        | TEXT              | VARCHAR(?)             |\n",
    "| continent           | TEXT              | VARCHAR(255)           |\n",
    "+---------------------+-------------------+------------------------+\n",
    "```\n",
    "There is a row that represents the business's website change the location column values from N/A to NULL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original schema for table dim_store_details: {'index': 'BIGINT', 'address': 'TEXT', 'longitude': 'DOUBLE PRECISION', 'lat': 'TEXT', 'locality': 'TEXT', 'store_code': 'TEXT', 'staff_numbers': 'BIGINT', 'opening_date': 'DATE', 'store_type': 'TEXT', 'latitude': 'DOUBLE PRECISION', 'country_code': 'TEXT', 'continent': 'TEXT'}\n",
      "Checking column 'longitude': current type is 'DOUBLE PRECISION', desired type is 'FLOAT'\n",
      "Checking column 'locality': current type is 'TEXT', desired type is 'VARCHAR(255)'\n",
      "Checking column 'store_code': current type is 'TEXT', desired type is 'VARCHAR(12)'\n",
      "Checking column 'staff_numbers': current type is 'BIGINT', desired type is 'SMALLINT'\n",
      "Checking column 'opening_date': current type is 'DATE', desired type is 'DATE'\n",
      "Checking column 'store_type': current type is 'TEXT', desired type is 'VARCHAR(255)'\n",
      "Checking column 'latitude': current type is 'DOUBLE PRECISION', desired type is 'FLOAT'\n",
      "Checking column 'country_code': current type is 'TEXT', desired type is 'VARCHAR(10)'\n",
      "Checking column 'continent': current type is 'TEXT', desired type is 'VARCHAR(255)'\n",
      "Executing SQL: ALTER TABLE dim_store_details ALTER COLUMN longitude SET DATA TYPE FLOAT USING longitude::FLOAT, ALTER COLUMN locality SET DATA TYPE VARCHAR(255) USING locality::VARCHAR(255), ALTER COLUMN store_code SET DATA TYPE VARCHAR(12) USING store_code::VARCHAR(12), ALTER COLUMN staff_numbers SET DATA TYPE SMALLINT USING staff_numbers::SMALLINT, ALTER COLUMN store_type SET DATA TYPE VARCHAR(255) USING store_type::VARCHAR(255), ALTER COLUMN latitude SET DATA TYPE FLOAT USING latitude::FLOAT, ALTER COLUMN country_code SET DATA TYPE VARCHAR(10) USING country_code::VARCHAR(10), ALTER COLUMN continent SET DATA TYPE VARCHAR(255) USING continent::VARCHAR(255);\n",
      "Schema updates applied successfully for dim_store_details.\n",
      "Current schema for table dim_store_details: {'index': 'BIGINT', 'address': 'TEXT', 'longitude': 'DOUBLE PRECISION', 'lat': 'TEXT', 'locality': 'VARCHAR(255)', 'store_code': 'VARCHAR(12)', 'staff_numbers': 'SMALLINT', 'opening_date': 'DATE', 'store_type': 'VARCHAR(255)', 'latitude': 'DOUBLE PRECISION', 'country_code': 'VARCHAR(10)', 'continent': 'VARCHAR(255)'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cols = ['store_code']\n",
    "# build connection with database\n",
    "with su.engine.connect() as connection:\n",
    "    # There is one store_code which mismatch in order_table and dim_store_details\n",
    "    # add a row in dim_store_details keep the data in order_table as it is valid\n",
    "    # # Define  SQL insert statement\n",
    "    # insert_sql = \"\"\"\n",
    "    # INSERT INTO dim_store_details \n",
    "    # (address, longitude, latitude, locality, store_code, staff_numbers, opening_date, store_type, country_code, continent) \n",
    "    # VALUES ('Unknown', 0.0, 0.0, 'Unknown', 'WEB-1388012W', 0, NULL, 'Unknown', 'Unknown', 'Unknown');\n",
    "    # \"\"\"\n",
    "    with connection.begin():\n",
    "        # connection.execute(text(insert_sql))\n",
    "        # print(\"Record inserted successfully.\")\n",
    "        max_lengths = get_max_lengths(connection, \"dim_store_details\", cols)\n",
    "        # Define the desired schema for the table\n",
    "        desired_store_details_schema = {\n",
    "            'longitude': 'FLOAT',\n",
    "            'locality': 'VARCHAR(255)',\n",
    "            'store_code': f'VARCHAR({max_lengths[\"store_code\"]})',  \n",
    "            'staff_numbers': 'SMALLINT',\n",
    "            'opening_date': 'DATE',\n",
    "            'store_type': 'VARCHAR(255)',  \n",
    "            'latitude': 'FLOAT',\n",
    "            'country_code': 'VARCHAR(10)', \n",
    "            'continent': 'VARCHAR(255)'\n",
    "        }\n",
    "\n",
    "    # Alter the specific table schema in that database\n",
    "    su.update_schema(connection, 'dim_store_details', desired_store_details_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Re-schema \"dim_products\" as seen in the table below.\n",
    "\n",
    "You will need to do some work on the products table before casting the data types correctly.\n",
    "\n",
    "The product_price column has a Â£ character which you need to remove using SQL.\n",
    "\n",
    "The team that handles the deliveries would like a new human-readable column added for the weight so they can quickly make decisions on delivery weights.\n",
    "\n",
    "Add a new column weight_class which will contain human-readable values based on the weight range of the product.\n",
    "```\n",
    "+--------------------------+-------------------+\n",
    "| weight_class VARCHAR(?)  | weight range(kg)  |\n",
    "+--------------------------+-------------------+\n",
    "| Light                    | < 2               |\n",
    "| Mid_Sized                | >= 2 - < 40       |\n",
    "| Heavy                    | >= 40 - < 140     |\n",
    "| Truck_Required           | => 140            |\n",
    "+----------------------------+-----------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original schema for table dim_products: {'product_name': 'TEXT', 'product_price': 'DOUBLE PRECISION', 'weight': 'DOUBLE PRECISION', 'category': 'TEXT', 'EAN': 'TEXT', 'date_added': 'DATE', 'uuid': 'TEXT', 'removed': 'TEXT', 'product_code': 'TEXT', 'weight_class': 'VARCHAR(20)'}\n",
      "Checking column 'product_name': current type is 'TEXT', desired type is 'VARCHAR(255)'\n",
      "Checking column 'product_price': current type is 'DOUBLE PRECISION', desired type is 'FLOAT'\n",
      "Checking column 'weight': current type is 'DOUBLE PRECISION', desired type is 'FLOAT'\n",
      "Checking column 'category': current type is 'TEXT', desired type is 'VARCHAR(255)'\n",
      "Checking column 'date_added': current type is 'DATE', desired type is 'DATE'\n",
      "Checking column 'uuid': current type is 'TEXT', desired type is 'UUID'\n",
      "Checking column 'removed': current type is 'TEXT', desired type is 'VARCHAR(20)'\n",
      "Checking column 'product_code': current type is 'TEXT', desired type is 'VARCHAR(11)'\n",
      "Executing SQL: ALTER TABLE dim_products ALTER COLUMN product_name SET DATA TYPE VARCHAR(255) USING product_name::VARCHAR(255), ALTER COLUMN product_price SET DATA TYPE FLOAT USING product_price::FLOAT, ALTER COLUMN weight SET DATA TYPE FLOAT USING weight::FLOAT, ALTER COLUMN category SET DATA TYPE VARCHAR(255) USING category::VARCHAR(255), ALTER COLUMN uuid SET DATA TYPE UUID USING uuid::UUID, ALTER COLUMN removed SET DATA TYPE VARCHAR(20) USING removed::VARCHAR(20), ALTER COLUMN product_code SET DATA TYPE VARCHAR(11) USING product_code::VARCHAR(11);\n",
      "Schema updates applied successfully for dim_products.\n",
      "Current schema for table dim_products: {'product_name': 'VARCHAR(255)', 'product_price': 'DOUBLE PRECISION', 'weight': 'DOUBLE PRECISION', 'category': 'VARCHAR(255)', 'EAN': 'TEXT', 'date_added': 'DATE', 'uuid': 'UUID', 'removed': 'VARCHAR(20)', 'product_code': 'VARCHAR(11)', 'weight_class': 'VARCHAR(20)'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build connection with the database\n",
    "with su.engine.connect() as connection:\n",
    "    cols_to_check = ['product_code']\n",
    "    max_lengths = get_max_lengths(connection, \"dim_products\", cols_to_check)\n",
    "\n",
    "    # Step 1: Alter the weight_class column to VARCHAR(20) to handle larger values\n",
    "    alter_weight_class_column_query = text(\"\"\"\n",
    "        ALTER TABLE dim_products \n",
    "        ADD COLUMN weight_class VARCHAR(20);                                   \n",
    "    \"\"\")\n",
    "    connection.execute(alter_weight_class_column_query)\n",
    "\n",
    "    # Step 2: Populate the weight_class column based on the weight range\n",
    "    update_weight_class_query = text(\"\"\"\n",
    "    UPDATE dim_products\n",
    "    SET weight_class = \n",
    "        CASE\n",
    "            WHEN weight < 2 THEN 'Light'\n",
    "            WHEN weight >= 2 AND weight < 40 THEN 'Mid_Sized'\n",
    "            WHEN weight >= 40 AND weight < 140 THEN 'Heavy'\n",
    "            WHEN weight >= 140 THEN 'Truck_Required'\n",
    "        END;\n",
    "    \"\"\")\n",
    "    \n",
    "    connection.execute(update_weight_class_query)\n",
    "\n",
    "    # Step 2: Define the desired schema for the products_table (excluding weight_class as it's newly added)\n",
    "    desired_products_table_schema = {\n",
    "        'product_name': 'VARCHAR(255)',\n",
    "        'product_price': 'FLOAT',\n",
    "        'weight': 'FLOAT',\n",
    "        'category': 'VARCHAR(255)',\n",
    "        'date_added': 'DATE',\n",
    "        'uuid': 'UUID',\n",
    "        'removed': 'VARCHAR(20)',\n",
    "        'product_code': f'VARCHAR({max_lengths[\"product_code\"]})'\n",
    "    }\n",
    "\n",
    "    # Alter the schema in the products_table (excluding weight_class)\n",
    "    su.update_schema(connection, 'dim_products', desired_products_table_schema)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5. Re-schema \"dim_date_times\" as seen in the table below.\n",
    "\n",
    "Now update the date table with the correct types:\n",
    "```\n",
    "+-----------------+-------------------+--------------------+\n",
    "| dim_date_times  | current data type | required data type |\n",
    "+-----------------+-------------------+--------------------+\n",
    "| month           | TEXT              | VARCHAR(?)         |\n",
    "| year            | TEXT              | VARCHAR(?)         |\n",
    "| day             | TEXT              | VARCHAR(?)         |\n",
    "| time_period     | TEXT              | VARCHAR(?)         |\n",
    "| date_uuid       | TEXT              | UUID               |\n",
    "+-----------------+-------------------+--------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original schema for table dim_date_times: {'timestamp': 'TEXT', 'month': 'BIGINT', 'year': 'BIGINT', 'day': 'BIGINT', 'time_period': 'TEXT', 'date_uuid': 'TEXT'}\n",
      "Checking column 'month': current type is 'BIGINT', desired type is 'VARCHAR(50)'\n",
      "Checking column 'year': current type is 'BIGINT', desired type is 'VARCHAR(50)'\n",
      "Checking column 'day': current type is 'BIGINT', desired type is 'VARCHAR(50)'\n",
      "Checking column 'time_period': current type is 'TEXT', desired type is 'VARCHAR(50)'\n",
      "Checking column 'date_uuid': current type is 'TEXT', desired type is 'UUID'\n",
      "Executing SQL: ALTER TABLE dim_date_times ALTER COLUMN month SET DATA TYPE VARCHAR(50) USING month::VARCHAR(50), ALTER COLUMN year SET DATA TYPE VARCHAR(50) USING year::VARCHAR(50), ALTER COLUMN day SET DATA TYPE VARCHAR(50) USING day::VARCHAR(50), ALTER COLUMN time_period SET DATA TYPE VARCHAR(50) USING time_period::VARCHAR(50), ALTER COLUMN date_uuid SET DATA TYPE UUID USING date_uuid::UUID;\n",
      "Schema updates applied successfully for dim_date_times.\n",
      "Current schema for table dim_date_times: {'timestamp': 'TEXT', 'month': 'VARCHAR(50)', 'year': 'VARCHAR(50)', 'day': 'VARCHAR(50)', 'time_period': 'VARCHAR(50)', 'date_uuid': 'UUID'}\n"
     ]
    }
   ],
   "source": [
    "# Build connection with the database\n",
    "with su.engine.connect() as connection:\n",
    "    # Step 1: Define the desired schema for the dim_date_time table\n",
    "    desired_dim_date_time_schema = {\n",
    "        'month': 'VARCHAR(50)',  # Adjust length as necessary\n",
    "        'year': 'VARCHAR(50)',   # Adjust length as necessary\n",
    "        'day': 'VARCHAR(50)',     # Adjust length as necessary\n",
    "        'time_period': 'VARCHAR(50)',  # Adjust length as necessary\n",
    "        'date_uuid': 'UUID'\n",
    "    }\n",
    "\n",
    "    # Alter the schema in the dim_date_time table\n",
    "    su.update_schema(connection, 'dim_date_times', desired_dim_date_time_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6. Re-schema \"dim_card_details\" as seen in the table below.\n",
    "\n",
    "Now we need to update the last table for the card details.\n",
    "\n",
    "Make the associated changes after finding out what the lengths of each variable should be:\n",
    "```\n",
    "+------------------------+-------------------+--------------------+\n",
    "|    dim_card_details    | current data type | required data type |\n",
    "+------------------------+-------------------+--------------------+\n",
    "| card_number            | TEXT              | VARCHAR(?)         |\n",
    "| expiry_date            | TEXT              | VARCHAR(?)         |\n",
    "| date_payment_confirmed | TEXT              | DATE               |\n",
    "+------------------------+-------------------+--------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original schema for table dim_card_details: {'card_number': 'TEXT', 'expiry_date': 'TEXT', 'card_provider': 'TEXT', 'date_payment_confirmed': 'DATE'}\n",
      "Checking column 'card_number': current type is 'TEXT', desired type is 'VARCHAR(19)'\n",
      "Checking column 'expiry_date': current type is 'TEXT', desired type is 'VARCHAR(7)'\n",
      "Checking column 'date_payment_confirmed': current type is 'DATE', desired type is 'DATE'\n",
      "Executing SQL: ALTER TABLE dim_card_details ALTER COLUMN card_number SET DATA TYPE VARCHAR(19) USING card_number::VARCHAR(19), ALTER COLUMN expiry_date SET DATA TYPE VARCHAR(7) USING expiry_date::VARCHAR(7);\n",
      "Schema updates applied successfully for dim_card_details.\n",
      "Current schema for table dim_card_details: {'card_number': 'VARCHAR(19)', 'expiry_date': 'VARCHAR(7)', 'card_provider': 'TEXT', 'date_payment_confirmed': 'DATE'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build connection with the database\n",
    "with su.engine.connect() as connection:\n",
    "    cols_to_check = ['card_number']\n",
    "    max_lengths = get_max_lengths(connection, \"dim_card_details\", cols_to_check)\n",
    "    # Step 1: Define the desired schema for the dim_card_details table\n",
    "    desired_dim_card_details_schema = {\n",
    "        'card_number': f'VARCHAR({max_lengths[\"card_number\"]})',  # Adjust length based on your requirements (max for card numbers)\n",
    "        'expiry_date': 'VARCHAR(7)',    # Format: MM/YYYY, hence 7 characters\n",
    "        'date_payment_confirmed': 'DATE'\n",
    "    }\n",
    "\n",
    "    # Alter the schema in the dim_card_details table\n",
    "    su.update_schema(connection, 'dim_card_details', desired_dim_card_details_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7. Set primary keys: \n",
    "Adding the primary keys to each of the tables prefixed with dim.\n",
    "\n",
    "Each table will serve the orders_table which will be the single source of truth for our orders.\n",
    "\n",
    "Check the column header of the orders_table you will see all but one of the columns exist in one of our tables prefixed with dim.\n",
    "\n",
    "We need to update the columns in the dim tables with a primary key that matches the same column in the orders_table.\n",
    "\n",
    "Using SQL, update the respective columns as primary key columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to add primary key constraints\n",
    "def add_primary_key(connection, table_name, column_name):\n",
    "    # Use the alter statement to add primary key\n",
    "\n",
    "    try:\n",
    "        sql_comm = f\"\"\"\n",
    "        ALTER TABLE {table_name} ADD PRIMARY KEY ({column_name});\n",
    "        \"\"\"\n",
    "        connection.execute(text(sql_comm))\n",
    "        print(text(sql_comm))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error adding primary key for {table_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ALTER TABLE dim_date_times ADD PRIMARY KEY (date_uuid);\n",
      "        \n",
      "\n",
      "\n",
      "        ALTER TABLE dim_users ADD PRIMARY KEY (user_uuid);\n",
      "        \n",
      "\n",
      "\n",
      "        ALTER TABLE dim_card_details ADD PRIMARY KEY (card_number);\n",
      "        \n",
      "\n",
      "\n",
      "        ALTER TABLE dim_store_details ADD PRIMARY KEY (store_code);\n",
      "        \n",
      "\n",
      "\n",
      "        ALTER TABLE dim_products ADD PRIMARY KEY (product_code);\n",
      "        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# primary key and table dictionary\n",
    "primary_keys_dict = {'dim_date_times': 'date_uuid', 'dim_users': 'user_uuid', 'dim_card_details': 'card_number', 'dim_store_details': 'store_code', 'dim_products': 'product_code'}\n",
    "# Set primary keys for each dim table\n",
    "with su.engine.connect() as connection:\n",
    "    # Start a transaction\n",
    "    with connection.begin():\n",
    "        for py_key in primary_keys_dict.keys():\n",
    "            try:\n",
    "                add_primary_key(connection, table_name=py_key, column_name=primary_keys_dict[py_key])\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary keys for dim_date_times: ['date_uuid']\n",
      "Primary keys for dim_users: ['user_uuid']\n",
      "Primary keys for dim_card_details: ['card_number']\n",
      "Primary keys for dim_store_details: ['store_code']\n",
      "Primary keys for dim_products: ['product_code']\n"
     ]
    }
   ],
   "source": [
    "# Check a table and confirm primary key:\n",
    "def check_primary_key(table_name):\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        kcu.column_name\n",
    "    FROM\n",
    "        information_schema.table_constraints AS tc\n",
    "    JOIN\n",
    "        information_schema.key_column_usage AS kcu\n",
    "        ON kcu.constraint_name = tc.constraint_name\n",
    "    WHERE\n",
    "        tc.table_name = '{table_name}'\n",
    "        AND tc.constraint_type = 'PRIMARY KEY';\n",
    "    \"\"\"\n",
    "\n",
    "    with su.engine.connect() as connection:\n",
    "        result = connection.execute(text(query))\n",
    "        primary_keys = [row[0] for row in result]\n",
    "        \n",
    "    return primary_keys\n",
    "\n",
    "# Example usage\n",
    "for table in primary_keys_dict.keys():\n",
    "    primary_keys = check_primary_key(table)\n",
    "    print(f\"Primary keys for {table}: {primary_keys}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8. create foreign keys:\n",
    "\n",
    "Create the foreign keys in the orders_table to reference the primary keys in the other tables.\n",
    "\n",
    "Use SQL to create those foreign key constraints that reference the primary keys of the other table.\n",
    "\n",
    "This makes the star-based database schema complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ALTER TABLE orders_table\n",
      "        ADD CONSTRAINT fk_orders_table_date_uuid\n",
      "        FOREIGN KEY (date_uuid)\n",
      "        REFERENCES dim_date_times(date_uuid);\n",
      "        \n",
      "\n",
      "        ALTER TABLE orders_table\n",
      "        ADD CONSTRAINT fk_orders_table_user_uuid\n",
      "        FOREIGN KEY (user_uuid)\n",
      "        REFERENCES dim_users(user_uuid);\n",
      "        \n",
      "\n",
      "        ALTER TABLE orders_table\n",
      "        ADD CONSTRAINT fk_orders_table_card_number\n",
      "        FOREIGN KEY (card_number)\n",
      "        REFERENCES dim_card_details(card_number);\n",
      "        \n",
      "\n",
      "        ALTER TABLE orders_table\n",
      "        ADD CONSTRAINT fk_orders_table_store_code\n",
      "        FOREIGN KEY (store_code)\n",
      "        REFERENCES dim_store_details(store_code);\n",
      "        \n",
      "\n",
      "        ALTER TABLE orders_table\n",
      "        ADD CONSTRAINT fk_orders_table_product_code\n",
      "        FOREIGN KEY (product_code)\n",
      "        REFERENCES dim_products(product_code);\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Define a function to add foreign key constraints\n",
    "def add_foreign_key(connection, table_name, column_name, ref_table, ref_column):\n",
    "    try:\n",
    "        sql_comm = f\"\"\"\n",
    "        ALTER TABLE {table_name}\n",
    "        ADD CONSTRAINT fk_{table_name}_{column_name}\n",
    "        FOREIGN KEY ({column_name})\n",
    "        REFERENCES {ref_table}({ref_column});\n",
    "        \"\"\"\n",
    "        connection.execute(text(sql_comm))\n",
    "        print(text(sql_comm))\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding foreign key for {table_name}: {e}\")\n",
    "\n",
    "# Define the relationships between orders_table and dim tables\n",
    "foreign_keys_dict = {\n",
    "    'dim_date_times': 'date_uuid',\n",
    "    'dim_users': 'user_uuid',\n",
    "    'dim_card_details': 'card_number',\n",
    "    'dim_store_details': 'store_code',\n",
    "    'dim_products': 'product_code'\n",
    "}\n",
    "\n",
    "# Apply foreign key constraints to orders_table\n",
    "with su.engine.connect() as connection:\n",
    "    for ref_table, ref_column in foreign_keys_dict.items():\n",
    "        try:\n",
    "            add_foreign_key(\n",
    "                connection, \n",
    "                table_name='orders_table', \n",
    "                column_name=ref_column, \n",
    "                ref_table=ref_table, \n",
    "                ref_column=ref_column\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
